"""
è·¨é¡µå•å…ƒæ ¼æ™ºèƒ½åˆ†ç±»å™¨
ä½¿ç”¨ AI æ¨¡å‹åˆ¤æ–­ä¸¤ä¸ªè·¨é¡µå•å…ƒæ ¼æ˜¯å¦æ˜¯åŒä¸€ä¸ªå•å…ƒæ ¼è¢«æˆªæ–­

åŸºäº Qwen3-32B æ¨¡å‹è¿›è¡Œæ™ºèƒ½åˆ¤æ–­
"""
from typing import Dict, Any, List, Tuple, Optional
from openai import OpenAI
import json


class PromptTemplates:
    """æç¤ºè¯æ¨¡æ¿ç±»"""

    # è¡Œçº§åˆ«æç¤ºè¯
    ROW_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PDFè¡¨æ ¼åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ¤æ–­è·¨é¡µè¡Œå†…å®¹æ˜¯å¦è¢«åˆ†é¡µç¬¦æˆªæ–­ã€‚

ä½ çš„ä»»åŠ¡ï¼š
åˆ¤æ–­ä¸¤è¡Œæ•°æ®æ˜¯å¦æ˜¯"è¡¨æ ¼ä¸­åŒä¸€è¡Œè¢«åˆ†é¡µæˆªæ–­"ï¼Œåªå…³æ³¨è¡Œå†…å®¹æœ¬èº«çš„è¿ç»­æ€§ã€‚

è¾“å…¥æ•°æ®æ ¼å¼ï¼š
- ä¸Šé¡µæœ€åä¸€è¡Œï¼šå¤šä¸ªå•å…ƒæ ¼çš„å†…å®¹ï¼ˆkey-valueæ ¼å¼ï¼‰
- ä¸‹é¡µç¬¬ä¸€è¡Œï¼šå¤šä¸ªå•å…ƒæ ¼çš„å†…å®¹ï¼ˆkey-valueæ ¼å¼ï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{
    "should_merge": true/false,
    "confidence": 0.95,
    "reason": "ç¬¬0åˆ—å†…å®¹æ˜æ˜¾è¢«æˆªæ–­ï¼Œåº”è¯¥åˆå¹¶"
}

**é‡è¦**ï¼šåªè¾“å‡º JSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
"""


class CrossPageCellClassifier:
    """ä½¿ç”¨ AI æ¨¡å‹åˆ¤æ–­è·¨é¡µå•å…ƒæ ¼æ˜¯å¦åº”è¯¥åˆå¹¶"""

    def __init__(
        self,
        model_name: str = "qwen3-14b",
        base_url: str = "http://112.111.54.86:10011/v1",
        api_key: str = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1aWQiOiIxOTE3MTIzNDc4NDI5ODg4NTEzIiwiZGVwdE5hbWUiOiIiLCJhcmVhQ29kZSI6IiIsInJvbGUiOiJjdXN0b20iLCJhcmVhTmFtZSI6IiIsImNyZWF0ZVRpbWUiOjE3NTg1OTY0ODQsImFwcElkIjoiMTAwMDAwMDAwMDAwMDAwMDAiLCJ0ZWxlcGhvbmUiOiIxODc1MDc5OTAxOSIsInVzZXJUeXBlIjoiaW5zaWRlIiwidXNlcm5hbWUiOiJjaGVueGlhb21pbiJ9.EtvuTHzkSfozetNefVBz4jMjhbHkGi3V-JtWp6_WebU",
        temperature: float = 0.4,  # æ ¹æ®APIç¤ºä¾‹è°ƒæ•´
        max_tokens: int = 8192,  # æ ¹æ®APIç¤ºä¾‹è°ƒæ•´
        top_p: float = 0.7,  # æ–°å¢å‚æ•°
        repetition_penalty: float = 1.05,  # æ–°å¢å‚æ•°
        truncate_length: int = 50  # å­—ç¬¦æˆªå–é•¿åº¦ï¼ˆå–æœ€å/æœ€å‰nä¸ªå­—ç¬¦ï¼‰
    ):
        """
        åˆå§‹åŒ–è·¨é¡µå•å…ƒæ ¼åˆ†ç±»å™¨

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º "qwen3-32b"
            base_url: API åœ°å€
            api_key: APIå¯†é’¥
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼‰ï¼Œè¶Šä½è¶Šç¡®å®š
            max_tokens: ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§ token æ•°
            truncate_length: å­—ç¬¦æˆªå–é•¿åº¦ï¼Œç”¨äºè¡Œçº§åˆ«åˆ¤æ–­
        """
        self.model_name = model_name
        self.base_url = base_url
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.top_p = top_p
        self.repetition_penalty = repetition_penalty
        self.truncate_length = truncate_length

        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )

        # ä»æç¤ºè¯æ¨¡æ¿ç±»åŠ è½½
        self.row_system_prompt = PromptTemplates.ROW_SYSTEM_PROMPT

        # éªŒè¯ API æ˜¯å¦å¯ç”¨
        self._check_api()

    def _check_api(self):
        """æ£€æŸ¥ API æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            models = self.client.models.list()
            print(f"[CellClassifier] API å·²è¿æ¥ï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
        except Exception as e:
            print(f"[CellClassifier] è­¦å‘Š: API è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            print(f"[CellClassifier] å°†åœ¨å®é™…è°ƒç”¨æ—¶éªŒè¯è¿æ¥")

    def _truncate_text(self, text: str, from_end: bool = True) -> str:
        """
        æˆªå–æ–‡æœ¬ï¼ˆå–æœ€å/æœ€å‰ n ä¸ªå­—ç¬¦ï¼‰

        Args:
            text: è¦æˆªå–çš„æ–‡æœ¬
            from_end: True=å–æœ€ånä¸ªå­—ç¬¦ï¼ŒFalse=å–æœ€å‰nä¸ªå­—ç¬¦

        Returns:
            æˆªå–åçš„æ–‡æœ¬
        """
        if not text:
            return text

        if len(text) <= self.truncate_length:
            return text

        if from_end:
            # å–æœ€å n ä¸ªå­—ç¬¦
            return "..." + text[-self.truncate_length:]
        else:
            # å–æœ€å‰ n ä¸ªå­—ç¬¦
            return text[:self.truncate_length] + "..."

    def classify_row_pairs_batch(
        self,
        row_pairs: List[Dict[str, Any]],
        max_retries: int = 3,
        retry_delay: float = 2.0
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ¤æ–­å¤šä¸ªè¡Œå¯¹æ˜¯å¦åº”è¯¥åˆå¹¶ï¼ˆè¡Œçº§åˆ«ï¼‰

        Args:
            row_pairs: è¡Œå¯¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ ¼å¼ï¼š
                {
                    "prev_row": {"ç¬¬0åˆ—": "å†…å®¹...", "ç¬¬1åˆ—": "5åˆ†", ...},
                    "next_row": {"ç¬¬0åˆ—": "å†…å®¹...", "ç¬¬1åˆ—": "", ...},
                    "context": {
                        "prev_table_id": "t1_p1",
                        "next_table_id": "t1_p2",
                        "prev_page": 1,
                        "next_page": 2,
                        "hint_score": 0.95
                    }
                }
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤2ç§’ï¼‰

        Returns:
            åˆ¤æ–­ç»“æœåˆ—è¡¨
        """
        if not row_pairs:
            return []

        print(f"[CellClassifier] æ‰¹é‡åˆ¤æ–­ {len(row_pairs)} ä¸ªè·¨é¡µè¡Œå¯¹...")

        # æ„å»ºæ‰¹é‡è¯·æ±‚
        user_content = self._build_batch_row_prompt(row_pairs)

        # æ‰“å°å‘é€çš„æ•°æ®
        print("\n" + "="*80)
        print("[CellClassifier] ğŸ“¤ å‘é€ç»™AIçš„æ•°æ®:")
        print("="*80)
        print(f"System Prompt:\n{self.row_system_prompt}\n")
        print(f"User Content:\n{user_content}")
        print("="*80 + "\n")

        # é‡è¯•é€»è¾‘
        import time
        last_error = None

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"[CellClassifier] é‡è¯• {attempt}/{max_retries-1}...")
                    time.sleep(retry_delay)

                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": self.row_system_prompt},
                        {"role": "user", "content": user_content}
                    ],
                    temperature=self.temperature,
                    max_tokens=self.max_tokens * len(row_pairs),  # æ‰¹é‡éœ€è¦æ›´å¤š tokens
                    top_p=self.top_p,
                    extra_body={
                        "repetition_penalty": self.repetition_penalty
                    },
                    timeout=60.0  # 60ç§’è¶…æ—¶
                )

                result_text = response.choices[0].message.content.strip()

                # æ‰“å°AIè¿”å›çš„æ•°æ®
                print("\n" + "="*80)
                print("[CellClassifier] ğŸ“¥ AIè¿”å›çš„æ•°æ®:")
                print("="*80)
                print(result_text)
                print("="*80 + "\n")

                # è§£ææ‰¹é‡ç»“æœ
                results = self._parse_batch_result(result_text, len(row_pairs))

                # æ‰“å°è§£æåçš„ç»“æœ
                print("\n" + "="*80)
                print("[CellClassifier] ğŸ“Š è§£æåçš„ç»“æœ:")
                print("="*80)
                for i, result in enumerate(results):
                    should_merge = result.get('should_merge', False)
                    confidence = result.get('confidence', 0)
                    reason = result.get('reason', 'N/A')
                    status = "âœ… åˆå¹¶" if should_merge else "âŒ ä¸åˆå¹¶"
                    print(f"è¡Œå¯¹ {i+1}: {status} (ç½®ä¿¡åº¦: {confidence:.2f}) - {reason}")
                print("="*80 + "\n")

                print(f"[CellClassifier] âœ… åˆ¤æ–­æˆåŠŸ")
                return results

            except Exception as e:
                last_error = e
                if attempt < max_retries - 1:
                    print(f"[CellClassifier] âš ï¸  è¯·æ±‚å¤±è´¥: {e}ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•...")
                else:
                    print(f"[CellClassifier] âŒ æ‰¹é‡åˆ¤æ–­å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {e}")

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
        return [
            {
                "should_merge": False,
                "confidence": 0.0,
                "reason": f"API è¯·æ±‚å¤±è´¥: {str(last_error)}",
                "error": str(last_error)
            }
            for _ in range(len(row_pairs))
        ]

    def _build_batch_row_prompt(self, row_pairs: List[Dict]) -> str:
        """æ„å»ºæ‰¹é‡è¡Œå¯¹åˆ¤æ–­çš„æç¤ºè¯"""
        prompt = "è¯·åˆ†æä»¥ä¸‹è·¨é¡µè¡¨æ ¼çš„è¡Œå¯¹ï¼Œåˆ¤æ–­æ¯ä¸€å¯¹æ˜¯å¦åº”è¯¥åˆå¹¶ï¼š\n\n"

        for i, pair in enumerate(row_pairs):
            prompt += f"## è¡Œå¯¹ {i+1}\n\n"

            # ä¸Šé¡µæœ€åä¸€è¡Œï¼ˆæˆªå–å­—ç¬¦ï¼‰
            prompt += f"**ä¸Šé¡µæœ€åä¸€è¡Œ**ï¼š\n"
            prev_row = pair.get('prev_row', {})
            for col, content in prev_row.items():
                truncated = self._truncate_text(content, from_end=True)  # å–æœ€ånä¸ªå­—ç¬¦
                prompt += f"  - {col}: {truncated}\n"

            # ä¸‹é¡µç¬¬ä¸€è¡Œï¼ˆæˆªå–å­—ç¬¦ï¼‰
            prompt += f"\n**ä¸‹é¡µç¬¬ä¸€è¡Œ**ï¼š\n"
            next_row = pair.get('next_row', {})
            for col, content in next_row.items():
                truncated = self._truncate_text(content, from_end=False)  # å–æœ€å‰nä¸ªå­—ç¬¦
                prompt += f"  - {col}: {truncated}\n"

            # ä¸Šä¸‹æ–‡ä¿¡æ¯
            if 'context' in pair:
                ctx = pair['context']
                prompt += f"\n**ä¸Šä¸‹æ–‡ä¿¡æ¯**ï¼š\n"
                prompt += f"  - é¡µç ï¼š{ctx.get('prev_page')} â†’ {ctx.get('next_page')}\n"
                prompt += f"  - Hintå¾—åˆ†ï¼š{ctx.get('hint_score', 0):.2f}\n"

            prompt += "\n" + "-" * 60 + "\n\n"

        prompt += """
è¯·å¯¹æ¯ä¸€å¯¹è¡Œè¾“å‡º JSON æ ¼å¼çš„åˆ¤æ–­ç»“æœï¼Œè¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼š
[
    {"should_merge": true/false, "confidence": 0.95, "reason": "..."},
    {"should_merge": true/false, "confidence": 0.90, "reason": "..."},
    ...
]

**é‡è¦**ï¼šåªè¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
"""
        return prompt

    def _parse_batch_result(self, result_text: str, expected_count: int) -> List[Dict[str, Any]]:
        """è§£ææ‰¹é‡ç»“æœ"""
        try:
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            if result_text.startswith("```json"):
                result_text = result_text[7:]
            if result_text.startswith("```"):
                result_text = result_text[3:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
            result_text = result_text.strip()

            results = json.loads(result_text)

            # éªŒè¯ç»“æœæ ¼å¼
            if not isinstance(results, list):
                raise ValueError("ç»“æœä¸æ˜¯æ•°ç»„")

            if len(results) != expected_count:
                print(f"[CellClassifier] è­¦å‘Š: æœŸæœ› {expected_count} ä¸ªç»“æœï¼Œå®é™…æ”¶åˆ° {len(results)} ä¸ª")

            # è¡¥å…¨ç¼ºå¤±çš„ç»“æœ
            while len(results) < expected_count:
                results.append({
                    "should_merge": False,
                    "confidence": 0.0,
                    "reason": "ç»“æœç¼ºå¤±"
                })

            # éªŒè¯æ¯ä¸ªç»“æœ
            for i, result in enumerate(results):
                if "should_merge" not in result:
                    results[i] = {
                        "should_merge": False,
                        "confidence": 0.0,
                        "reason": "ç»“æœæ ¼å¼é”™è¯¯",
                        "error": "Missing 'should_merge' field"
                    }

            return results[:expected_count]

        except (json.JSONDecodeError, ValueError) as e:
            print(f"[CellClassifier] JSON è§£æå¤±è´¥: {e}")
            print(f"[CellClassifier] åŸå§‹å“åº”: {result_text[:200]}...")
            # è¿”å›é»˜è®¤ç»“æœ
            return [
                {
                    "should_merge": False,
                    "confidence": 0.0,
                    "reason": f"JSON è§£æå¤±è´¥: {str(e)}",
                    "error": "Parse error"
                }
                for _ in range(expected_count)
            ]


if __name__ == '__main__':
    # ç®€å•æµ‹è¯•ï¼ˆå¦‚éœ€æµ‹è¯•ï¼Œä½¿ç”¨ test_row_classifier.pyï¼‰
    print("è·¨é¡µè¡Œçº§åˆ«åˆ†ç±»å™¨ - ä½¿ç”¨ test_row_classifier.py è¿›è¡Œæµ‹è¯•")