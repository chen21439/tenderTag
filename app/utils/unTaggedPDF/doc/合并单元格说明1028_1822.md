# 跨页表格合并问题诊断与修复方案

**创建时间**: 2025-10-28 18:22
**状态**: 实验性方案，存在诡异问题，待revert后重新评估

---

## 一、问题背景

### 1.1 核心问题
页面5-6的表格无法正确合并（之前页面4-5可以正常合并）

### 1.2 问题表现
```
页5 表3 (temp_006):
  - 第一轮检测: 3列
  - bbox起点: x0=33.6

页6 表1 (temp_007):
  - 第一轮检测: 4列
  - bbox起点: x0=99.0 (应该是33.6)
  - **缺失最左侧"序号"列**

结果: 列数不匹配 (3 vs 4)，合并被拒绝
```

### 1.3 根本原因分析

**pdfplumber的列检测策略问题**:
- 默认使用 `vertical_strategy: "lines"`
- **只检测有实际垂直线分隔的列**
- 如果某列左右没有垂直线，会被忽略

**本案例具体原因**:
1. 页6表格最左侧"序号"列缺少左边界垂直线
2. pdfplumber未检测到该列
3. 导致bbox从99.0开始，而不是33.6
4. 列数从5减少到4

---

## 二、解决方案设计

### 2.1 整体架构：两阶段提取 + Continuation Hints

```
阶段1: 第一轮提取
  ↓
  使用pdfplumber默认设置提取所有表格
  保存为 tables_first_round (用于调试)
  ↓
阶段2: 生成Continuation Hints
  ↓
  分析页底/页顶表格，提取列边界模板
  保存为 hints_by_page (用于调试)
  ↓
阶段3: 基于Hints重新提取
  ↓
  使用上一页的列边界强制重新提取下一页
  保存为 tables_before_merge (用于调试)
  ↓
阶段4: 跨页合并
  ↓
  合并列数匹配的续页表格
  输出最终结果 tables
```

### 2.2 Continuation Hints机制

**目的**: 将上一页表格的列结构传递给下一页

**生成条件**:
```python
# 在 CrossPageTableMerger.build_continuation_hints() 中
1. 上一页表格在页面底部 (y1 > page_height - 10%)
2. 下一页表格在页面顶部 (y0 < page_height * 20%)
3. 列边界对齐分数 >= 0.95
```

**Hint内容**:
```python
{
  "source_table_id": "temp_006",  # 模板来源
  "score": 0.95,                   # 置信度
  "explicit_vertical_lines": [     # 强制列边界
    33.6, 231.1, 429.1, 495.1, 561.1
  ],
  "v_strategy": "explicit",
  "h_strategy": "lines"
}
```

### 2.3 二次提取流程（B档方案）

在 `TableExtractor.reextract_with_hints()` 中实现：

#### 路线A: 使用explicit_vertical_lines强制提取
```python
settings = {
    "explicit_vertical_lines": hint["explicit_vertical_lines"],
    "vertical_strategy": "explicit",
    "horizontal_strategy": "lines"
}
```

#### 路线B: Text Bucketing Fallback
如果路线A失败，使用文本位置推断列：
```python
settings = {
    "vertical_strategy": "text",
    "horizontal_strategy": "lines",
    "text_x_tolerance": 3
}
```

#### 匹配与替换逻辑
```python
# 通过IoU (Intersection over Union) 匹配原表格
if IoU >= 0.65:
    if new_cols == old_cols or new_cols > old_cols:
        # 替换原表格
    else:
        # 保留原表格（列数反而减少了）
```

---

## 三、代码修改点

### 3.1 pdf_content_extractor.py

**新增内容**:
1. 导入 `datetime` 用于时间戳
2. 保存三个调试数据集：
   - `tables_first_round`: 第一轮原始提取
   - `tables_before_merge`: 重提取后的结果
   - `hints_by_page`: continuation hints信息

**修改的方法**:
```python
def extract_all_tables(self):
    # 第一轮提取
    tables = self.table_extractor.extract_tables()
    tables_first_round = copy.deepcopy(tables)

    # 第二轮：生成hints并重新提取
    if self.enable_cross_page_merge:
        hints_by_page = self.cross_page_merger.build_continuation_hints(...)
        if hints_by_page:
            tables = self.table_extractor.reextract_with_hints(hints_by_page, tables)
            tables_before_merge = copy.deepcopy(tables)

    # 第三轮：跨页合并
    tables = self.cross_page_merger.merge_all_tables(...)

    # 返回结果包含所有调试信息
    return {
        "tables": tables,
        "tables_first_round": tables_first_round,
        "tables_before_merge": tables_before_merge,
        "hints_by_page": hints_by_page
    }
```

### 3.2 table_extractor.py

**新增方法**:
```python
def reextract_with_hints(self, hints_by_page, original_tables):
    """使用continuation hints重新提取指定页面的表格"""

    for page_num, hint in hints_by_page.items():
        # 路线A: explicit columns
        new_table = extract_table(page, bbox, hint_settings)

        # 路线B: text bucketing (fallback)
        if not new_table or len(new_table) < 2:
            new_table = extract_table(page, bbox, text_settings)

        # 匹配并替换原表格
        for orig in original_tables:
            if IoU(new_bbox, orig_bbox) >= 0.65:
                if should_replace:
                    # 替换
                break
```

### 3.3 cross_page_merger.py

**新增方法**:
```python
def build_continuation_hints(self, tables, page_widths, page_heights, page_drawings):
    """为可能的续页表格生成列边界hints"""

    hints = {}
    for i, prev_table in enumerate(tables):
        if i + 1 >= len(tables):
            continue

        next_table = tables[i + 1]

        # 检查是否跨页
        if prev_table['page'] != next_table['page']:
            # 检查位置（页底 + 页顶）
            if is_bottom(prev) and is_top(next):
                # 生成hint
                hints[next_page] = {
                    "source_table_id": prev_id,
                    "explicit_vertical_lines": extract_columns(prev),
                    "score": alignment_score
                }

    return hints
```

### 3.4 时间戳修改

所有JSON输出文件名添加时间戳：
```python
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
filename = f"{task_id}_table_{timestamp}.json"
```

**影响的文件**:
- `pdf_content_extractor.py`: table.json, paragraph.json
- `section_tagger.py`: tagged.json
- `test_hints.py`: table_raw.json

---

## 四、调试数据结构

### 4.1 tables_first_round
```json
[
  {
    "id": "temp_006",
    "page": 5,
    "columns": 3,  // 第一轮只检测到3列
    "bbox": [33.6, 359.49, 561.1, 2614.92]
  },
  {
    "id": "temp_007",
    "page": 6,
    "columns": 4,  // 第一轮检测到4列（缺序号列）
    "bbox": [99.0, 28.8, 561.1, 702.79]  // x0错误
  }
]
```

### 4.2 hints_by_page
```json
{
  "6": {
    "source_table_id": "temp_006",
    "score": 0.95,
    "explicit_vertical_lines": [
      33.6,   // 期望的左边界
      231.1,
      429.1,
      495.1,
      561.1
    ],
    "v_strategy": "explicit",
    "h_strategy": "lines"
  }
}
```

### 4.3 tables_before_merge
重提取后的结果（理论上应该修正了列数）

---

## 五、已知问题与诡异现象

### 5.1 问题现象
- ⚠️ 用户报告存在"诡异的问题"（具体未详述）
- ⚠️ 需要revert代码重新评估

### 5.2 可能的问题点

#### 问题1: 重提取导致数据质量下降
**现象**: 强制使用列边界可能导致文字被错误分配
**原因**: explicit_vertical_lines可能不精确
**示例**:
```
原始: 自然分列，文字完整
重提取: 强制分列，文字被切分
```

#### 问题2: IoU阈值设置不当
**现象**: 重提取的表格与原表格匹配失败
**当前阈值**: 0.65
**影响**:
- 太高: 无法匹配，hint不生效
- 太低: 误匹配，替换错误表格

#### 问题3: Fallback逻辑冲突
**现象**: 两个fallback路线可能产生不一致结果
**路线A**: explicit_vertical_lines（强制）
**路线B**: text bucketing（推断）
**问题**: 何时该用A，何时该用B？

#### 问题4: 列边界提取不准确
**现象**: 从raw_bbox提取的列边界可能不完整
**原因**: pdfplumber的cells数据可能缺失
**影响**: hint中的explicit_vertical_lines不完整

---

## 六、后续优化方向

### 6.1 短期修复（如果继续这个方案）

1. **增强列边界提取**
   ```python
   # 不只从cells提取，还要从drawings提取垂直线
   vertical_lines = extract_from_drawings(page_drawings)
   columns = merge(cells_columns, vertical_lines)
   ```

2. **调整IoU阈值**
   ```python
   # 根据表格大小动态调整
   iou_threshold = 0.65 if bbox_area < 1000 else 0.75
   ```

3. **优化fallback优先级**
   ```python
   # 先尝试text，再尝试explicit
   if text_result.quality > explicit_result.quality:
       use text_result
   ```

### 6.2 长期方案（替代方案）

#### 方案1: 预处理阶段统一使用text策略
```python
# 第一轮就用text strategy
settings = {
    "vertical_strategy": "text",
    "horizontal_strategy": "lines"
}
```

#### 方案2: 基于视觉的列检测
```python
# 使用OpenCV检测表格线
import cv2
vertical_lines = detect_vertical_lines(page_image)
```

#### 方案3: 放弃pdfplumber，使用其他库
- Camelot
- Tabula
- PaddleOCR + 表格识别

---

## 七、回滚建议

### 7.1 需要回滚的文件
```
app/utils/unTaggedPDF/pdf_content_extractor.py
app/utils/unTaggedPDF/table_extractor.py
app/utils/unTaggedPDF/cross_page_merger.py
test_hints.py
```

### 7.2 保留的修改
- 时间戳功能（可以保留，无副作用）
- 调试数据输出结构（tables_first_round等，便于分析）

### 7.3 回滚后的下一步
1. 仔细分析 `table_raw.json` 和 `hints_by_page`
2. 手工验证列边界是否正确
3. 考虑更简单的解决方案（如全局使用text strategy）

---

## 八、测试验证

### 8.1 测试命令
```bash
.venv/Scripts/python.exe test_hints.py
```

### 8.2 检查点
- [ ] tables_first_round 是否准确反映第一轮提取
- [ ] hints_by_page 中的列边界是否正确
- [ ] tables_before_merge 是否成功修正列数
- [ ] 最终合并是否成功
- [ ] 合并后的表格内容是否完整

### 8.3 对比文件
```
国土空间规划实施监测网络建设项目_table_raw_{timestamp}.json
国土空间规划实施监测网络建设项目_table_{timestamp}.json
```

---

## 九、总结

### 9.1 核心思路
通过Continuation Hints机制，将上一页表格的列结构传递给下一页，强制重新提取以保持列数一致。

### 9.2 关键挑战
- pdfplumber的列检测策略限制
- 列边界提取的准确性
- 重提取与原表格的匹配逻辑
- 多个fallback路线的协调

### 9.3 当前状态
⚠️ **实验性方案，存在诡异问题，建议revert后重新评估**

### 9.4 经验教训
1. 表格提取本质上是个"脏活"，完美方案不存在
2. 过度工程化可能引入更多问题
3. 简单方案（如全局text strategy）可能更可靠
4. 需要大量真实案例测试验证

---

**文档结束**
如有问题，请参考 `tables_first_round` 和 `hints_by_page` 调试数据